{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo abaixo é mostrado como fazer o treinamento de uma rede neural bem simples para classificar o dataset MNIST, o dataset MNIST é um conjunto de dígitos escritos a mão de 0 a 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- total trainning batch number: 600\n",
      " -- total testing batch number: 100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "## carrega o dataset mnist\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "    \n",
    "# function utilizado para fazer a normalização\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "\n",
    "# carrega o dataset MNIST, caso esse não exista, faz o download\n",
    "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# instancia o dataloader utilizando o dataset MNIST\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "\n",
    "print (' -- total trainning batch number: {0}'.format(len(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dset.MNIST` carrega o dataset MNIST, caso esse ainda não exista, esse método faz o download. O argumento trans é um function utilizado para normalizar os dados do MNIST.\n",
    "`DataLoader` instância o dataload que será utilizado durante o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc4): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# definição do modelo\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 300)\n",
    "        self.fc2 = nn.Linear(300, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir o seu modelo no PyTorch você deve criar uma classe que herda de `nn.Module`. O design do PyTorch é fortemente baseado em orientação a objetos.\n",
    "A classe do seu modelo precisa implementar o método  `forward`, assim o esqueleto da classe que representa o nosso modelo é:\n",
    "```\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "```\n",
    "No método `__ini__` são instanciados os objetos utilizados no modelo, nesse caso as camadas que serão utilizadas no modelo. No nosso caso serão utilizadas 3 camadas lineares.\n",
    "\n",
    "`torch.nn.Linear(in_features, out_features, bias=True)` essa é a assinatura do objeto Linear, o primeiro argumento é número de features de entrada, o segundo é o número de features de saída e o terceiro especifica se terá ou não bias. Como sabemos o tamanho das imagens do MNIST é 28x28 pixels monocromáticos, ou seja, apenas em tons de cinza.\n",
    "\n",
    "O método `forward` é onde essas camadas são conectadas. Uma atenção bem grande deve ser dada às conexões das camadas, o argumento `x` representa a entrada do modelo, é por ele que irá fluir o nosso tensor de entrada.\n",
    "\n",
    "`x = x.view(-1, 28*28)`: O método `view` modifica o shape do tensor, e no caso o argumento -1 diz para o método que nós não sabemos quantas linhas tem o nosso tensor, note que apenas um parâmetro pode ser -1 no método `view`.\n",
    "\n",
    "As próximas linhas conectam uma camada na outra, algo que pode gerar alguma confusão é o tipo do parâmetro `x`.\n",
    "`torch::Tensor forward(torch::Tensor x)` Essa é a assinatura da API do PyTorch em C++, `forward` recebe e retorna um tensor, portanto, funções como `F.relu` também retornam um tensor.\n",
    "\n",
    "O fato das camadas como Linear serem definidos no construtor, enquanto a relu ser apenas uma função que é conectada no método `forward`, se deve ao fato que Linear possui parâmetros (pesos), e não apenas uma função matemática que modifica o tensor de entrada como é o caso das funções de ativação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 0, batch index: 100, train loss: 1.9767781496047974\n",
      "==>>> epoch: 0, batch index: 200, train loss: 0.5577573776245117\n",
      "==>>> epoch: 0, batch index: 300, train loss: 0.3963330090045929\n",
      "==>>> epoch: 0, batch index: 400, train loss: 0.21971210837364197\n",
      "==>>> epoch: 0, batch index: 500, train loss: 0.25142425298690796\n",
      "==>>> epoch: 0, batch index: 600, train loss: 0.27990201115608215\n",
      "==>>> epoch: 1, batch index: 100, train loss: 0.2895001769065857\n",
      "==>>> epoch: 1, batch index: 200, train loss: 0.15145011246204376\n",
      "==>>> epoch: 1, batch index: 300, train loss: 0.2328670471906662\n",
      "==>>> epoch: 1, batch index: 400, train loss: 0.24531914293766022\n",
      "==>>> epoch: 1, batch index: 500, train loss: 0.1771671175956726\n",
      "==>>> epoch: 1, batch index: 600, train loss: 0.15539273619651794\n",
      "==>>> epoch: 2, batch index: 100, train loss: 0.37194594740867615\n",
      "==>>> epoch: 2, batch index: 200, train loss: 0.12438665330410004\n",
      "==>>> epoch: 2, batch index: 300, train loss: 0.12461578100919724\n",
      "==>>> epoch: 2, batch index: 400, train loss: 0.1315932422876358\n",
      "==>>> epoch: 2, batch index: 500, train loss: 0.19791610538959503\n",
      "==>>> epoch: 2, batch index: 600, train loss: 0.11764700710773468\n",
      "==>>> epoch: 3, batch index: 100, train loss: 0.0639018714427948\n",
      "==>>> epoch: 3, batch index: 200, train loss: 0.1298096626996994\n",
      "==>>> epoch: 3, batch index: 300, train loss: 0.3355529010295868\n",
      "==>>> epoch: 3, batch index: 400, train loss: 0.10434451699256897\n",
      "==>>> epoch: 3, batch index: 500, train loss: 0.2082432508468628\n",
      "==>>> epoch: 3, batch index: 600, train loss: 0.08949398994445801\n",
      "==>>> epoch: 4, batch index: 100, train loss: 0.0854153260588646\n",
      "==>>> epoch: 4, batch index: 200, train loss: 0.16651703417301178\n",
      "==>>> epoch: 4, batch index: 300, train loss: 0.16374200582504272\n",
      "==>>> epoch: 4, batch index: 400, train loss: 0.051357436925172806\n",
      "==>>> epoch: 4, batch index: 500, train loss: 0.17444568872451782\n",
      "==>>> epoch: 4, batch index: 600, train loss: 0.15846502780914307\n",
      "==>>> epoch: 5, batch index: 100, train loss: 0.0945349633693695\n",
      "==>>> epoch: 5, batch index: 200, train loss: 0.067236989736557\n",
      "==>>> epoch: 5, batch index: 300, train loss: 0.102035291492939\n",
      "==>>> epoch: 5, batch index: 400, train loss: 0.10783065855503082\n",
      "==>>> epoch: 5, batch index: 500, train loss: 0.07691483944654465\n",
      "==>>> epoch: 5, batch index: 600, train loss: 0.07642512768507004\n",
      "==>>> epoch: 6, batch index: 100, train loss: 0.1591457724571228\n",
      "==>>> epoch: 6, batch index: 200, train loss: 0.1289600431919098\n",
      "==>>> epoch: 6, batch index: 300, train loss: 0.0925246924161911\n",
      "==>>> epoch: 6, batch index: 400, train loss: 0.07725455611944199\n",
      "==>>> epoch: 6, batch index: 500, train loss: 0.022121911868453026\n",
      "==>>> epoch: 6, batch index: 600, train loss: 0.0757741928100586\n",
      "==>>> epoch: 7, batch index: 100, train loss: 0.03361998870968819\n",
      "==>>> epoch: 7, batch index: 200, train loss: 0.0406792126595974\n",
      "==>>> epoch: 7, batch index: 300, train loss: 0.06328120827674866\n",
      "==>>> epoch: 7, batch index: 400, train loss: 0.03680542856454849\n",
      "==>>> epoch: 7, batch index: 500, train loss: 0.08725012838840485\n",
      "==>>> epoch: 7, batch index: 600, train loss: 0.033590469509363174\n",
      "==>>> epoch: 8, batch index: 100, train loss: 0.05878501385450363\n",
      "==>>> epoch: 8, batch index: 200, train loss: 0.04858461767435074\n",
      "==>>> epoch: 8, batch index: 300, train loss: 0.09484919905662537\n",
      "==>>> epoch: 8, batch index: 400, train loss: 0.09701070934534073\n",
      "==>>> epoch: 8, batch index: 500, train loss: 0.026902036741375923\n",
      "==>>> epoch: 8, batch index: 600, train loss: 0.05314929783344269\n",
      "==>>> epoch: 9, batch index: 100, train loss: 0.057075273245573044\n",
      "==>>> epoch: 9, batch index: 200, train loss: 0.030561048537492752\n",
      "==>>> epoch: 9, batch index: 300, train loss: 0.02029186673462391\n",
      "==>>> epoch: 9, batch index: 400, train loss: 0.05309654399752617\n",
      "==>>> epoch: 9, batch index: 500, train loss: 0.10022180527448654\n",
      "==>>> epoch: 9, batch index: 600, train loss: 0.0166034959256649\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# instância o algoritmo de otimização SGD para atualizar os parâmetros do nosso modelo\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# instância a função de perda\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    # itera sobre o data loader para gerar lotes do conjunto de dados\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        # reseta os gradientes\n",
    "        optimizer.zero_grad()\n",
    "        # transfere o tensor para o device utilizado\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        # executa o modelo nos dados de entrada\n",
    "        out = model(x)\n",
    "        # calcula o valor de perda para comparar com o nosso modelo\n",
    "        loss = criterion(out, target)\n",
    "        # calcula o gradiente da perda calculada no nosso modelo\n",
    "        loss.backward()\n",
    "        # atualiza os parâmetros do nosso modelo baseado no cálculo do gradiente\n",
    "        optimizer.step()\n",
    "        # imprime a época, o batch e a perda periodicamente a cada 100 batches         \n",
    "        if (batch_idx+1) % 100 == 0 or (batch_idx+1) == len(train_loader):\n",
    "            print ('==>>> epoch: {0}, batch index: {1}, train loss: {2}'.format(\n",
    "                epoch, batch_idx+1, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora possa ter variações, esse é o formato básico padrão do loop de treinamento utilizado pelo PyTorch. Os comentários em cada linha diz que cada chamada faz.\n",
    "\n",
    "O loop começa com uma chamada de `zero_grad` para zerar o gradiente, isso é necessário pois o PyTorch acumula o gradiente, isso é útil em redes recorrentes e em vários outros casos, então, se não é esse o nosso caso, temos que zerar o gradiente.\n",
    "Os próximos passos é basicamente calcular a predição para os dados de entrada utilizando com os parâmetros que temos no momento, e comparar com a predição anotada, então precisamos calcular o gradiente utilizando a função de otimização escolhida, que no nosso caso foi SGD, e então atualizamos os parâmetros do nosso modelo utilizando o gradiente calculado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importa o pacote para plotar imagens\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# a cada execução pega a próxima imagem e plota essa imagem\n",
    "(example_data, _) = next(iter(train_loader))\n",
    "fig = plt.figure()\n",
    "plt.imshow(example_data[0][0], cmap='gray', interpolation='none')\n",
    "fig\n",
    "\n",
    "# faz a predição da imagem no modelo\n",
    "out = model(example_data[0][0])\n",
    "\n",
    "# pega o máximo valor do tensor e o seu indice\n",
    "values, indices = torch.max(out, 1)\n",
    "\n",
    "# imprime o indice que corresponde exatamente ao número\n",
    "print(\"number: \", int(indices[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse é um exemplo básico de como fazer a predição por um modelo treinado no PyTorch. É claro que na prática você nunca vai querer prever um dado que fez parte do conjunto de treinamento, mas para demonstrar como a coisa funciona, apesar de totalmente errado conceitualmente, por enquanto serve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
